{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from d3rlpy.dataset import MDPDataset\n",
    "from d3rlpy.algos import DiscreteDecisionTransformer, DiscreteDecisionTransformerConfig\n",
    "from d3rlpy.models import SGDFactory\n",
    "\n",
    "import torch\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # File path\n",
    "participants = ['p1_2022-07-25', 'p2_2022-08-03', 'p3_2022-08-04', 'p4_2022-08-10', 'p5_2022-08-12', \n",
    "                'p6_2022-08-15', 'p7_2022-08-15', 'p8_2022-08-19', 'p9_2022-08-22', 'p10_2022-08-26', \n",
    "                'p11_2022-08-29', 'p12_2022-08-29', 'p13_2022-08-29', 'p14_2022-08-31', 'p15_2022-09-02', \n",
    "                'p16_2022-09-05', 'p17_2022-09-06', 'p18_2022-09-07', 'p19_2022-09-08', 'p20_2022-09-09']\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for participant in participants:\n",
    "    file_path = 'Data/' + participant + '.csv'\n",
    "    df = pd.read_csv(file_path, low_memory = False)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "for i in range(len(df_list)):\n",
    "    df_list[i]['handover quality'].fillna('NEUTRAL', inplace = True)\n",
    "    df_list[i]['handover type'].fillna('NEITHER', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to one-hot encoding\n",
    "arm_status_mapping = {'STATIONARY': 0, 'REACHING': 1, 'TUCKING': 2}\n",
    "base_status_mapping = {'STATIONARY': 0, 'TO OPERATOR': 1, 'ROTATING': 2, 'TO PARTICIPANT': 3}\n",
    "handover_status_mapping = {'LEFT': 0, 'MIDDLE': 1, 'RIGHT': 2}\n",
    "handover_quality_mapping = {'BAD': -10, 'NEUTRAL': 0, 'GOOD': 10}\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    df_list[i]['arm status'] = df_list[i]['arm status'].map(arm_status_mapping).astype('category')\n",
    "    df_list[i]['base status'] = df_list[i]['base status'].map(base_status_mapping).astype('category')\n",
    "    df_list[i]['handover status'] = df_list[i]['handover status'].map(handover_status_mapping).astype('category')\n",
    "    df_list[i]['handover quality'] = df_list[i]['handover quality'].map(handover_quality_mapping).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation and test set\n",
    "np.random.seed(48)\n",
    "\n",
    "test_df_list = []\n",
    "train_df_list = []\n",
    "\n",
    "for i in range(int(len(df_list) * 0.8)):\n",
    "    train_df_list.append(df_list[i])\n",
    "\n",
    "for i in range(int(len(df_list) * 0.8), len(df_list)):\n",
    "    test_df_list.append(df_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the arm observation states\n",
    "gripper_x_column_index = train_df_list[0].columns.get_loc('gripper (x)')\n",
    "gripper_qw_column_index = train_df_list[0].columns.get_loc('gripper (qw)')\n",
    "\n",
    "train_arm_data = torch.cat([torch.tensor(arm.iloc[:, gripper_x_column_index:gripper_qw_column_index + 1].values) for arm in train_df_list], dim = 0)\n",
    "\n",
    "# Get the handover observation states\n",
    "handover_z_column_index = train_df_list[0].columns.get_loc('handover_goal (x)')\n",
    "handover_qw_column_index = train_df_list[0].columns.get_loc('handover_goal (qw)')\n",
    "\n",
    "train_handover_data = torch.cat([torch.tensor(handover.iloc[:, handover_z_column_index:handover_qw_column_index + 1].values) for handover in train_df_list], dim = 0)\n",
    "\n",
    "# Get the remaining observation states\n",
    "starting_observations_column_index = train_df_list[0].columns.get_loc('neutral (global)')\n",
    "ending_observations_column_index = train_df_list[0].columns.get_loc('right_hip (confidence)')\n",
    "\n",
    "train_base_observations = torch.cat([torch.tensor(train_df.iloc[:, starting_observations_column_index:ending_observations_column_index + 1].values) for train_df in train_df_list], dim = 0)\n",
    "train_arm_observations = torch.cat((train_arm_data, torch.cat([torch.tensor(train_df.iloc[:, starting_observations_column_index:ending_observations_column_index + 1].values) for train_df in train_df_list], dim = 0)), dim = 1)\n",
    "train_handover_observations = torch.cat((train_handover_data, torch.cat([torch.tensor(train_df.iloc[:, starting_observations_column_index:ending_observations_column_index + 1].values) for train_df in train_df_list], dim = 0)), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arm_data = torch.cat([torch.tensor(arm.iloc[:, gripper_x_column_index:gripper_qw_column_index + 1].values) for arm in test_df_list], dim = 0)\n",
    "\n",
    "test_handover_data = torch.cat([torch.tensor(handover.iloc[:, handover_z_column_index:handover_qw_column_index + 1].values) for handover in test_df_list], dim = 0)\n",
    "\n",
    "test_base_observations = torch.cat([torch.tensor(test_df.iloc[:, starting_observations_column_index:ending_observations_column_index + 1].values) for test_df in test_df_list], dim = 0)\n",
    "test_arm_observations = torch.cat((test_arm_data, torch.cat([torch.tensor(test_df.iloc[:, starting_observations_column_index:ending_observations_column_index + 1].values) for test_df in test_df_list], dim = 0)), dim = 1)\n",
    "test_handover_observations = torch.cat((test_handover_data, torch.cat([torch.tensor(test_df.iloc[:, starting_observations_column_index:ending_observations_column_index + 1].values) for test_df in test_df_list], dim = 0)), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the action states\n",
    "train_arm_status_action = torch.cat([torch.tensor(arm_status_action['arm status'].values) for arm_status_action in train_df_list])\n",
    "train_base_status_action = torch.cat([torch.tensor(base_status_action['base status'].values) for base_status_action in train_df_list])\n",
    "train_handover_status_action = torch.cat([torch.tensor(handover_status_action['handover status'].values) for handover_status_action in train_df_list])\n",
    "\n",
    "# Get the rewards states\n",
    "train_rewards = torch.cat([torch.tensor(reward['handover quality'].values) for reward in train_df_list])\n",
    "\n",
    "# Get the terminals states\n",
    "train_episode = torch.cat([torch.tensor(episode['episode'].values) for episode in train_df_list])\n",
    "episode_indices = torch.where(train_episode[1:] != train_episode[:-1])\n",
    "train_terminals = torch.zeros_like(train_episode)\n",
    "train_terminals[episode_indices] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the action states\n",
    "test_arm_status_action = torch.cat([torch.tensor(arm_status_action['arm status'].values) for arm_status_action in test_df_list])\n",
    "test_base_status_action = torch.cat([torch.tensor(base_status_action['base status'].values) for base_status_action in test_df_list])\n",
    "test_handover_status_action = torch.cat([torch.tensor(handover_status_action['handover status'].values) for handover_status_action in test_df_list])\n",
    "\n",
    "# Get the rewards states\n",
    "test_rewards = torch.cat([torch.tensor(reward['handover quality'].values) for reward in test_df_list])\n",
    "\n",
    "# Get the terminals states\n",
    "test_episode = torch.cat([torch.tensor(episode['episode'].values) for episode in test_df_list])\n",
    "episode_indices = torch.where(test_episode[1:] != test_episode[:-1])\n",
    "test_terminals = torch.zeros_like(test_episode)\n",
    "test_terminals[episode_indices] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_timestep = 0\n",
    "max_timestep = 0\n",
    "\n",
    "for item in train_terminals:\n",
    "    if item == 0:\n",
    "        current_timestep += 1\n",
    "        max_timestep = max(max_timestep, current_timestep)\n",
    "    else:\n",
    "        current_timestep = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with arm status as action state\n",
    "arm_status_dataset = MDPDataset(\n",
    "    observations = train_arm_observations.numpy(),\n",
    "    actions = train_arm_status_action.numpy(),\n",
    "    rewards = train_rewards.numpy(),\n",
    "    terminals = train_terminals.numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(seq1, seq2):\n",
    "    str1 = ''.join(map(str, seq1))\n",
    "    str2 = ''.join(map(str, seq2))\n",
    "    \n",
    "    return Levenshtein.distance(str1, str2)\n",
    "\n",
    "def model_plotting(data, data_type, dataset, prediction, action, action_state):\n",
    "    for i in range(len(data)):\n",
    "        plt.figure(figsize = (20, 125))\n",
    "\n",
    "        for j, episode in enumerate(data[i]['episode'].unique()):\n",
    "            indices = data[i].index[data[i]['episode'] == episode].tolist()\n",
    "            current_participant_predicition = np.sum(prediction[indices] != action[indices])\n",
    "            \n",
    "            plt.subplot(len(data[i]['episode'].unique()), 1, j + 1)\n",
    "            plt.plot(prediction[indices], label = 'Prediction')\n",
    "            plt.plot(action[indices], label = 'Action')\n",
    "\n",
    "            if action_state == 'arm status':\n",
    "                plt.yticks([0, 1, 2], ['STATIONARY', 'REACHING', 'TUCKING'])\n",
    "                plt.ylabel('Arm status')\n",
    "            elif action_state == 'base status':\n",
    "                plt.yticks([0, 1, 2, 3], ['STATIONARY', 'TO OPERATOR', 'ROTATING', 'TO PARTICIPANT'])\n",
    "                plt.ylabel('Base status')\n",
    "            elif action_state == 'handover status':\n",
    "                plt.yticks([0, 1, 2], ['LEFT', 'MIDDLE', 'RIGHT'])\n",
    "                plt.ylabel('Handover status')\n",
    "\n",
    "            plt.title(f'{participants[i + 16]} Episode {episode} - Incorrect Prediction: {current_participant_predicition} / {len(indices)}')\n",
    "            plt.xlabel('Time step')\n",
    "            plt.legend(loc = 'lower right')\n",
    "\n",
    "        plt.suptitle(f'{data_type.title()} Set', fontsize = 20, color = 'red')\n",
    "        plt.tight_layout(rect = [0, 0, 1, 0.98])\n",
    "        plt.savefig(f'Output Week 9 - S2/{dataset}/{action_state}/{data_type}_' + participants[i + 16] + '.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Arm status\n",
    "dt_arm_status = DiscreteDecisionTransformer(config = DiscreteDecisionTransformerConfig(max_timestep = max_timestep, learning_rate = 0.0001, batch_size = 256, optim_factory = SGDFactory(momentum = 0.9, weight_decay = 1e-5)), device = 'cuda:0')\n",
    "\n",
    "# Train the model\n",
    "dt_arm_status.fit(arm_status_dataset, n_steps = 500000, n_steps_per_epoch = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the action\n",
    "dt_arm_status_wrapper = dt_arm_status.as_stateful_wrapper(target_return = 1000)\n",
    "\n",
    "dt_arm_status_test_prediction = []\n",
    "for observation, reward in zip(test_arm_observations.numpy(), test_rewards.numpy()):\n",
    "    dt_arm_status_test_prediction.append(dt_arm_status_wrapper.predict(observation, reward))\n",
    "\n",
    "dt_arm_status_test_prediction = np.array(dt_arm_status_test_prediction)\n",
    "\n",
    "# Plot the accuracy of the model\n",
    "model_plotting(data = test_df_list,\n",
    "                data_type = 'test',\n",
    "                dataset = 'instantaneous',\n",
    "                prediction = dt_arm_status_test_prediction,\n",
    "                action = test_arm_status_action.numpy(),\n",
    "                action_state = 'arm status')\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "test_arm_distance_list = []\n",
    "test_arm_indices_list = []\n",
    "\n",
    "for i in range(len(test_df_list)):\n",
    "    test_arm_distance = []\n",
    "    test_arm_indices = []\n",
    "\n",
    "    for _, episode in enumerate(test_df_list[i]['episode'].unique()):\n",
    "        indices = test_df_list[i].index[test_df_list[i]['episode'] == episode].tolist()\n",
    "        test_arm_distance.append(levenshtein_distance(test_arm_status_action.numpy()[indices], dt_arm_status_test_prediction[indices]))\n",
    "        test_arm_indices.append(indices)\n",
    "    test_arm_distance_list.append(test_arm_distance)\n",
    "    test_arm_indices_list.append(test_arm_indices)\n",
    "\n",
    "arm_table = PrettyTable(['Metrics', 'Test'])\n",
    "\n",
    "test_arm_result1 = []\n",
    "test_arm_result2 = []\n",
    "test_arm_result3 = []\n",
    "test_arm_result4 = []\n",
    "test_arm_result5 = []\n",
    "test_arm_result6 = []\n",
    "\n",
    "for i in range(len(test_df_list)):\n",
    "    test_arm_result1.append(np.mean(test_arm_distance_list[i]))\n",
    "    test_arm_result2.append(np.median(test_arm_distance_list[i]))\n",
    "    test_arm_result3.append(np.std(test_arm_distance_list[i]))\n",
    "    test_arm_result4.append(np.mean([len(indices) for indices in test_arm_indices_list[i]]))\n",
    "    test_arm_result5.append(np.median([len(indices) for indices in test_arm_indices_list[i]]))\n",
    "    test_arm_result6.append(np.std([len(indices) for indices in test_arm_indices_list[i]]))\n",
    "\n",
    "arm_result = {\n",
    "    'Mean Distance': f'{np.mean(test_arm_result1):.2f}',\n",
    "    'Median Distance': f'{np.mean(test_arm_result2):.2f}',\n",
    "    'Std Distance': f'{np.mean(test_arm_result3):.2f}',\n",
    "    'Mean Episode Length': f'{np.mean(test_arm_result4):.2f}',\n",
    "    'Median Episode Length': f'{np.mean(test_arm_result5):.2f}',\n",
    "    'Std Episode Length': f'{np.mean(test_arm_result6):.2f}'\n",
    "}\n",
    "\n",
    "for key, value in arm_result.items():\n",
    "    arm_table.add_row([key, value])\n",
    "\n",
    "print(arm_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
